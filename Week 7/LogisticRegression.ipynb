{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogisticRegression.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "XAvsA5amwFX9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import time\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "start_time = datetime.datetime.now()\n",
        "\n",
        "# 1. Загрузим данные: в X_train запишем признаки, не связанные с итогами матча, в y_train - исходы матчей\n",
        "data = pd.read_csv('./features.csv', index_col='match_id')\n",
        "X_train = pd.DataFrame(data.loc[:, 'start_time':'dire_first_ward_time'])\n",
        "y_train = pd.DataFrame(data['radiant_win'])\n",
        "X_test = pd.read_csv('./features_test.csv', index_col='match_id')\n",
        "\n",
        "# 1.1 Заполним NaN значения нулями\n",
        "X_train = X_train.fillna(0)\n",
        "X_test = X_test.fillna(0)\n",
        "\n",
        "# 1.2 Выполним масштабирование признаков\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 1.3 Выберем разбиение\n",
        "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
        "\n",
        "# 1.4 Обучим классификатор и проверим качество на кросс-валидации\n",
        "for coef in [0.01, 0.1, 0.5, 1.0, 3.0, 10.0]:\n",
        "  clf = LogisticRegression(penalty='l2', C=coef)\n",
        "  clf.fit(X_train_scaled, y_train)\n",
        "  c_v = cross_val_score(clf, X_train_scaled, y_train, cv=kf, scoring='roc_auc')\n",
        "  print('{c} L2 coef = {p}'.format(c = round(c_v.mean(), 6), p=coef))\n",
        "  print ('Time elapsed:', datetime.datetime.now() - start_time)\n",
        "\n",
        "#0.71655  L2 coef = 0.01 Время выполнения ~ 35s\n",
        "#0.716527 L2 coef = 0.1\n",
        "#0.716523 L2 coef = 0.5 \n",
        "#0.716523 L2 coef = 1.0 \n",
        "#0.716522 L2 coef = 3.0\n",
        "#0.716522 L2 coef = 10.0\n",
        "\n",
        "# 2.1 Удалим категориальный признаки\n",
        "\n",
        "X_train_ = X_train.drop(columns=['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', \\\n",
        "                                                      'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero'])\n",
        "X_test_ = X_test.drop(columns=['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', \\\n",
        "                                                      'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero'])\n",
        "\n",
        "scaler_ = StandardScaler()\n",
        "X_train_scaled_ = scaler.fit_transform(X_train_)\n",
        "X_test_scaled_ = scaler.transform(X_test_)\n",
        "\n",
        "# 2.2 Обучим классификатор и проверим качество на кросс-валидации\n",
        "for coef in [0.01, 0.1, 0.5, 1.0, 3.0, 10.0]:\n",
        "  clf = LogisticRegression(penalty='l2', C=0.01)\n",
        "  clf.fit(X_train_scaled_, y_train)\n",
        "  c_v = cross_val_score(clf, X_train_scaled_, y_train, cv=kf, scoring='roc_auc')\n",
        "  print('{c} L2 coef = {p}'.format(c = round(c_v.mean(), 6), p=coef))\n",
        "  print ('Time elapsed:', datetime.datetime.now() - start_time)\n",
        "  \n",
        "#0.716559 L2 coef = 0.01 Время выполнения ~ 30s\n",
        "#0.716534 L2 coef = 0.1\n",
        "#0.716531 L2 coef = 0.5\n",
        "#0.71653  L2 coef = 1.0\n",
        "#0.71653  L2 coef = 3.0\n",
        "#0.71653  L2 coef = 10.0\n",
        "\n",
        "# В сравнении с градиентным бустингом получается результат с меньшим значением качества на кросс-валидации\n",
        "# Объяснение - логистическая регрессия - линейный классификатор, а градиентный бустинг - нелинейный.\n",
        "# Градиентный бустинг лучше восстанавливает нелинейные зависимости\n",
        "\n",
        "# Время работы логистической регрессии существенно ниже времени работы градиентного бустинга при большом количестве деревьев\n",
        "\n",
        "#Видим, что качество улучшилось, но незначительно, в 3-4 знаке, вывод - исключение категориальных признаков не вносит существенный вклад\n",
        "#Как можно объяснить - логистическая регрессия не дает существенные веса признакам, которые не вносят существенный вклад в предсказание\n",
        "\n",
        "# 3. N — количество различных героев в выборке\n",
        "# Взял max, чтобы не падало на цикле ниже, так как есть пропуски по героям в исходной выборке\n",
        "# Согласно справочника героев, всего их 113, в нашем случае 112 герой - максимальный\n",
        "N = X_train['r1_hero'].unique().max()\n",
        "\n",
        "# 4.1 Воспользуемся подходом 'мешок слов' для train и test (test нужен для получения финального предсказания)\n",
        "X_pick_train = np.zeros((X_train.shape[0], N))\n",
        "X_pick_test = np.zeros((X_test.shape[0], N))\n",
        "\n",
        "for i, match_id in enumerate(X_train.index):\n",
        "    for p in range(5):\n",
        "        X_pick_train[i, X_train.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
        "        X_pick_train[i, X_train.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
        "        \n",
        "for i, match_id in enumerate(X_test.index):\n",
        "    for p in range(5):\n",
        "        X_pick_test[i, X_test.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
        "        X_pick_test[i, X_test.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
        "        \n",
        "X_pick_train = pd.DataFrame(X_pick_train, index = X_train.index)\n",
        "X_pick_test = pd.DataFrame(X_pick_test, index = X_test.index)\n",
        "\n",
        "# 4.2 Добавим наши новые признаки, очистим от неинформативных признаков, выполним масштабирование\n",
        "X_train_add = pd.concat((X_train, X_pick_train), axis = 1)\n",
        "X_test_add = pd.concat((X_test, X_pick_test), axis = 1)\n",
        "\n",
        "X_train_add_ = X_train_add.drop(columns=['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', \\\n",
        "                                                      'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero'])\n",
        "X_test_add_ = X_test_add.drop(columns=['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', \\\n",
        "                                                      'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero'])\n",
        "\n",
        "scaler_ = StandardScaler()\n",
        "X_train_scaled_add = scaler.fit_transform(X_train_add_)\n",
        "X_test_scaled_add = scaler.transform(X_test_add_)\n",
        "\n",
        "# 5.1 Обучим классификатор и проверим качество на кросс-валидации\n",
        "#for coef in [0.01, 0.1, 0.5, 1.0, 3.0, 10.0]:\n",
        "clf = LogisticRegression(penalty='l2', C=0.01)\n",
        "clf.fit(X_train_scaled_add, y_train)\n",
        "c_v = cross_val_score(clf, X_train_scaled_add, y_train, cv=kf, scoring='roc_auc')\n",
        "print('{c} L2 coef = {p}'.format(c = round(c_v.mean(), 6), p=coef))\n",
        "print ('Time elapsed:', datetime.datetime.now() - start_time)\n",
        "\n",
        "# 0.751964 L2 coef = 0.01\n",
        "# Видим, что качество значительно улучшилось, то есть наше предположение, о том, что некоторые выигрывают чаще, оказалось верным\n",
        "\n",
        "# 6. Построим предсказания:\n",
        "pred = pd.Series(clf.predict_proba(X_test_scaled_add)[:, 1], name = 'radiant_win', index = X_test.index)\n",
        "\n",
        "# >> c_v\n",
        "# array([0.74934397, 0.75315468, 0.7495552 , 0.75609852, 0.75166785])\n",
        "# модель адекватная, получилась не константной\n",
        "\n",
        "# 7. Сохраним наши результаты и загрузим на kaggle\n",
        "#X_test_final = pd.concat([X_test, pred], axis=1, ignore_index = True)\n",
        "#res = pd.Series(X_test_final[102])\n",
        "#res.to_csv('./submission_log.csv')\n",
        "#грузим на kaggle, получаем score = 0.75526 на public leaderbord"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}